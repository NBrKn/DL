{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One time run code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(imgf, labelf, outf, n):\n",
    "    f = open(imgf, \"rb\")\n",
    "    o = open(outf, \"w\")\n",
    "    l = open(labelf, \"rb\")\n",
    "\n",
    "    f.read(16)\n",
    "    l.read(8)\n",
    "    images = []\n",
    "\n",
    "    for i in range(n):\n",
    "        image = [ord(l.read(1))]\n",
    "        for j in range(28*28):\n",
    "            image.append(ord(f.read(1)))\n",
    "        images.append(image)\n",
    "\n",
    "    for image in images:\n",
    "        o.write(\",\".join(str(pix) for pix in image)+\"\\n\")\n",
    "    f.close()\n",
    "    o.close()\n",
    "    l.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert(\"./data/train-images-idx3-ubyte\", \"./data/train-labels-idx1-ubyte\",\n",
    "        \"data/mnist_train.csv\", 60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert(\"./data/t10k-images-idx3-ubyte\", \"./data/t10k-labels-idx1-ubyte\",\n",
    "        \"./data/mnist_test.csv\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/mnist_train.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = training[:, 0].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training[:, 1:].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/mnist_test.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = test[:, 0].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[:, 1:].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = pd.get_dummies(Y_train).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = pd.get_dummies(Y_test).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLu(x, derivative=False):\n",
    "    if(derivative==False):\n",
    "        return x*(x > 0)\n",
    "    else:\n",
    "        return 1*(x > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Softmax(x):\n",
    "    x -= np.max(x)\n",
    "    sm = (np.exp(x).T / np.sum(np.exp(x),axis=1)).T\n",
    "    return sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateWeights(wl1, wl2):\n",
    "    ##Initialization of the Weights and the Biases with the random gaussian function with mean zeron, and variance between 1/sqtr(num_inputs_layer)\n",
    "    \n",
    "    ninputs = 784\n",
    "    nclass = 10 ##Numer of the class, in this case it is the number of the digits.\n",
    "    \n",
    "    #layer1\n",
    "    w1 = np.random.normal(0, ninputs**-0.5, [ninputs,wl1])\n",
    "    b1 = np.random.normal(0, ninputs**-0.5, [1,wl1])\n",
    "    \n",
    "    #Layer2\n",
    "    w2 = np.random.normal(0, wl1**-0.5, [wl1,wl2])\n",
    "    b2 = np.random.normal(0, wl1**-0.5, [1,wl2])\n",
    "\n",
    "    #Layer3\n",
    "    w3 = np.random.normal(0, wl2**-0.5, [wl2,nclass])\n",
    "    b3 = np.random.normal(0, wl2**-0.5, [1,nclass])\n",
    "    \n",
    "    return [w1,w2,w3,b1,b2,b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dropout(x, keep_prop):\n",
    "    mask = np.random.binomial([np.ones_like(x)],(1-keep_prop))[0]  / (1-keep_prop)\n",
    "    return x*mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(weights, x, keep_prop=0):\n",
    "    \n",
    "    w1,w2,w3,b1,b2,b3  = weights \n",
    "    \n",
    "    #1-Hidden Layer\n",
    "    first = ReLu(x@w1+b1)\n",
    "    first = Dropout(first, keep_prop)\n",
    "\n",
    "    #2-Hidden Layer\n",
    "    second = ReLu(first@w2+b2)\n",
    "    second = Dropout(second, keep_prop)\n",
    "    \n",
    "    #Output Layer\n",
    "    return [first, second, Softmax(second@w3+b3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, y):\n",
    "    hit = 0\n",
    "    output = np.argmax(output, axis=1)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    for y in zip(output, y):\n",
    "        if(y[0]==y[1]):\n",
    "            hit += 1\n",
    "\n",
    "    p = (hit*100)/output.shape[0]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log2(x):\n",
    "    if(x!=0):\n",
    "        return np.log(x)\n",
    "    else:\n",
    "        return -np.inf\n",
    "    \n",
    "def log(y):\n",
    "    return [[log2(nx) for nx in x]for x in y]\n",
    "\n",
    "def cost(Y_predict, Y_right):\n",
    "    \n",
    "    Loss = -np.mean((np.nan_to_num(Y_right*log(Y_predict)) + np.nan_to_num((1-Y_right)*log(1-Y_predict))),keepdims=True)\n",
    "    return Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_valid = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADAM(weights, x, t, outputs, eta, beta1, beta2, eps, i, nabla, cache=None):\n",
    "    \n",
    "    w1,w2,w3,b1,b2,b3  = weights\n",
    "    \n",
    "    \n",
    "    if(cache==None):\n",
    "            vw1 = np.zeros_like(w1)\n",
    "            mw1 = np.zeros_like(w1)\n",
    "            \n",
    "            vw2 = np.zeros_like(w2)\n",
    "            mw2 = np.zeros_like(w2)\n",
    "            \n",
    "            vw3 = np.zeros_like(w3)\n",
    "            mw3 = np.zeros_like(w3)\n",
    "            \n",
    "            vb1 = np.zeros_like(b1)\n",
    "            mb1 = np.zeros_like(b1)\n",
    "            \n",
    "            vb2 = np.zeros_like(b2)\n",
    "            mb2 = np.zeros_like(b2)\n",
    "            \n",
    "            vb3 = np.zeros_like(b3)\n",
    "            mb3 = np.zeros_like(b3)\n",
    "    else:\n",
    "        vw1,mw1,vw2,mw2,vw3,mw3,vb1,mb1,vb2,mb2,vb3,mb3 = cache\n",
    "    \n",
    "    first, second, y = outputs\n",
    "   \n",
    "    w3_delta = (t-y)/x.shape[0]\n",
    "    \n",
    "    w2_error = w3_delta@w3.T\n",
    "\n",
    "    w2_delta = w2_error * ReLu(second,derivative=True)\n",
    "\n",
    "    w1_error = w2_delta@w2.T\n",
    "    w1_delta = w1_error * ReLu(first,derivative=True)\n",
    "    \n",
    "    \n",
    "    dw3 = (second.T@w3_delta + nabla*w3)\n",
    "    mw3 = beta1*mw3 + (1-beta1)*dw3\n",
    "    mt = (mw3) / (1-beta1**i)\n",
    "    vw3 = beta2*vw3 + (1-beta2)*(dw3**2)\n",
    "    vt = (vw3) / (1-beta2**i)\n",
    "    w3 += eta * mt/(np.sqrt(vt) + eps)\n",
    "    \n",
    "    db3 = (w3_delta.sum(axis=0)+ nabla*b3)\n",
    "    mb3 = beta1*mb3 + (1-beta1)*db3\n",
    "    mt = (mb3) / (1-beta1**i)\n",
    "    vb3 = beta2*vb3 + (1-beta2)*(db3**2)\n",
    "    vt = (vb3) / (1-beta2**i)\n",
    "    b3 += eta * mt/(np.sqrt(vt) + eps)\n",
    "    \n",
    "    dw2 = (first.T@w2_delta + nabla*w2)\n",
    "    mw2 = beta1*mw2 + (1-beta1)*dw2\n",
    "    mt = (mw2) / (1-beta1**i)\n",
    "    vw2 = beta2*vw2 + (1-beta2)*(dw2**2)\n",
    "    vt = (vw2) / (1-beta2**i)\n",
    "    w2 += eta * mt/(np.sqrt(vt) + eps)\n",
    "    \n",
    "    db2 = (w2_delta.sum(axis=0) + nabla*b2)\n",
    "    mb2 = beta1*mb2 + (1-beta1)*db2\n",
    "    mt = (mb2) / (1-beta1**i)\n",
    "    vb2 = beta2*vb2 + (1-beta2)*(db2**2)\n",
    "    vt = (vb2) / (1-beta2**i)\n",
    "    b2 += eta * mt/(np.sqrt(vt) + eps)\n",
    "    \n",
    "    dw1 = (x.T@w1_delta + nabla*w1)\n",
    "    mw1 = beta1*mw1 + (1-beta1)*dw1\n",
    "    mt = (mw1) / (1-beta1**i)\n",
    "    vw1 = beta2*vw1 + (1-beta2)*(dw1**2)\n",
    "    vt = (vw1) / (1-beta2**i)\n",
    "    w1 += eta * mt/(np.sqrt(vt) + eps)\n",
    "    \n",
    "    db1 = (w1_delta.sum(axis=0) + nabla*b1)\n",
    "    mb1 = beta1*mb1 + (1-beta1)*db1\n",
    "    mt = (mb1) / (1-beta1**i)\n",
    "    vb1 = beta2*vb1 + (1-beta2)*(db1**2)\n",
    "    vt = (vb1) / (1-beta2**i)\n",
    "    b1 += eta * mt/(np.sqrt(vt) + eps)\n",
    "    \n",
    "    \n",
    "    weights = [w1,w2,w3,b1,b2,b3]\n",
    "    cache = [vw1,mw1,vw2,mw2,vw3,mw3,vb1,mb1,vb2,mb2,vb3,mb3]\n",
    "    \n",
    "    return weights, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "def elastic_transform(image, alpha, sigma, random_state=None):\n",
    "    \"\"\"Elastic deformation of images as described in [Simard2003]_.\n",
    "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "       Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "       Proc. of the International Conference on Document Analysis and\n",
    "       Recognition, 2003.\n",
    "    \"\"\"\n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState(None)\n",
    "\n",
    "    shape = image.shape\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "\n",
    "    x, y = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]))\n",
    "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1))\n",
    "\n",
    "    return map_coordinates(image, indices, order=1).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(weights, x_train, y_train, x_valid, y_valid, epochs = 10, nbatchs=25, alpha = 1e-3, decay = 0, beta1=0.9, beta2=0.999, eps=1e-8, l2 = 0.001, keep_prop = 0):\n",
    "    \n",
    "    pross = x_train.shape[0]*0.05\n",
    "    \n",
    "    history = [[],[]]\n",
    "    \n",
    "    index = np.arange(x_train.shape[0])\n",
    "    cache = None\n",
    "    print(\"Train data: %d\" % (x_train.shape[0]))\n",
    "    print(\"Validation data: %d \\n\" % (x_valid.shape[0]))\n",
    "    mtime = 0\n",
    "    inter_adam = 1\n",
    "    \n",
    "    for j in range(epochs):\n",
    "        np.random.shuffle(index)\n",
    "        t = 0\n",
    "        iterations = round(x_train.shape[0]/nbatchs)\n",
    "        prog = \"\"\n",
    "        sacurr = 0\n",
    "        sloss = 0\n",
    "        sys.stdout.write(\"\\nEpochs: %2d \\ %2d \\n\"% (j+1,epochs))\n",
    "        stime = 0\n",
    "        timeIT = time.time()\n",
    "        for i in range(iterations):\n",
    "            timeI = time.time()\n",
    "            f = i*nbatchs\n",
    "            l = f+nbatchs\n",
    "            \n",
    "            if(l>(x_train.shape[0]-1)):\n",
    "                l = x_train.shape[0]\n",
    "                \n",
    "            x = np.array([elastic_transform(xx.reshape(28,28),15,3).reshape(784) for xx in x_train[index[f:l]]])\n",
    "            y = y_train[index[f:l]]\n",
    "\n",
    "            outputs = predict(weights, x, keep_prop)\n",
    "            \n",
    "            loss = cost(outputs[-1], y)+ l2 * (np.mean(weights[0],keepdims=True)**2+np.mean(weights[1],keepdims=True)**2+np.mean(weights[2],keepdims=True)**2)/3\n",
    "            \n",
    "            \n",
    "            accuracy_t = accuracy(outputs[-1], y)\n",
    "            \n",
    "            sacurr += accuracy_t\n",
    "            sloss += loss\n",
    "            \n",
    "            accuracy_train = sacurr/(i+1)\n",
    "            loss_train = sloss/(i+1)\n",
    "            \n",
    "            weights, cache = ADAM(weights, x, y, outputs, alpha, beta1, beta2, eps, inter_adam, l2, cache)\n",
    "            \n",
    "            t+= x.shape[0]\n",
    "            \n",
    "            qtd = round(t/pross)\n",
    "            prog = \"[\"\n",
    "            for p in range(20):\n",
    "                if(p<qtd-1):\n",
    "                    prog += \"=\"\n",
    "                elif(p==qtd-1):\n",
    "                    prog += \">\"\n",
    "                else:\n",
    "                    prog += \".\"\n",
    "            prog += \"]\"\n",
    "\n",
    "            \n",
    "            stime += time.time()-timeI\n",
    "            mtime = stime/(i+1)\n",
    "            mTimeT = mtime * (iterations-i-1)\n",
    "            \n",
    "            sys.stdout.write(\"\\r%5d/%5d %s ETA: %3d s - loss: %.4f  acc: %.4f\" % (t, x_train.shape[0], prog, mTimeT, loss_train, accuracy_train))\n",
    "            \n",
    "            history[0].append([loss_train, accuracy_train])\n",
    "            inter_adam += 1\n",
    "        mtime = time.time()-timeIT\n",
    "        alpha = alpha - (alpha*decay)\n",
    "        \n",
    "        outputs = predict(weights, x_valid)\n",
    "        \n",
    "        loss_valid = cost(outputs[-1], y_valid)+ l2 * (np.mean(weights[0],keepdims=True)**2+np.mean(weights[1],keepdims=True)**2+np.mean(weights[2],keepdims=True)**2)/3\n",
    "        accuracy_valid = accuracy(outputs[-1], y_valid)\n",
    "        \n",
    "        sys.stdout.write(\"\\r%5d/%5d %s ETA: %3d s loss: %.4f  acc: %.4f - lossValid: %.4f  accValid: %.4f \" % ( t, x_train.shape[0], prog, mtime, loss_train, accuracy_train, loss_valid, accuracy_valid))\n",
    "        history[1].append([loss_valid, accuracy_valid])\n",
    "        \n",
    "    return weights, history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = CreateWeights(784, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 60000\n",
      "Validation data: 10000 \n",
      "\n",
      "\n",
      "Epochs:  1 \\ 60 \n",
      "60000/60000 [===================>] ETA: 130 s loss: 0.0590  acc: 89.0917 - lossValid: 0.0155  accValid: 97.3600 \n",
      "Epochs:  2 \\ 60 \n",
      "60000/60000 [===================>] ETA: 129 s loss: 0.0317  acc: 94.4483 - lossValid: 0.0122  accValid: 97.8900 \n",
      "Epochs:  3 \\ 60 \n",
      "60000/60000 [===================>] ETA: 130 s loss: 0.0258  acc: 95.4500 - lossValid: 0.0102  accValid: 98.1200 \n",
      "Epochs:  4 \\ 60 \n",
      "60000/60000 [===================>] ETA: 130 s loss: 0.0221  acc: 96.0850 - lossValid: 0.0076  accValid: 98.6300 \n",
      "Epochs:  5 \\ 60 \n",
      "60000/60000 [===================>] ETA: 130 s loss: 0.0196  acc: 96.5300 - lossValid: 0.0072  accValid: 98.7700 \n",
      "Epochs:  6 \\ 60 \n",
      "60000/60000 [===================>] ETA: 130 s loss: 0.0180  acc: 96.8133 - lossValid: 0.0064  accValid: 98.8300 \n",
      "Epochs:  7 \\ 60 \n",
      "60000/60000 [===================>] ETA: 129 s loss: 0.0168  acc: 97.0667 - lossValid: 0.0061  accValid: 98.8800 \n",
      "Epochs:  8 \\ 60 \n",
      "60000/60000 [===================>] ETA: 130 s loss: 0.0157  acc: 97.2600 - lossValid: 0.0061  accValid: 98.8800 \n",
      "Epochs:  9 \\ 60 \n",
      "60000/60000 [===================>] ETA: 130 s loss: 0.0147  acc: 97.3500 - lossValid: 0.0058  accValid: 98.9600 \n",
      "Epochs: 10 \\ 60 \n",
      "60000/60000 [===================>] ETA: 130 s loss: 0.0145  acc: 97.4767 - lossValid: 0.0052  accValid: 99.1100 \n",
      "Epochs: 11 \\ 60 \n",
      "60000/60000 [===================>] ETA: 131 s loss: 0.0135  acc: 97.6433 - lossValid: 0.0054  accValid: 98.9800 \n",
      "Epochs: 12 \\ 60 \n",
      "60000/60000 [===================>] ETA: 129 s loss: 0.0130  acc: 97.7367 - lossValid: 0.0051  accValid: 99.0900 \n",
      "Epochs: 13 \\ 60 \n",
      "60000/60000 [===================>] ETA: 130 s loss: 0.0124  acc: 97.8933 - lossValid: 0.0050  accValid: 99.1300 \n",
      "Epochs: 14 \\ 60 \n",
      "60000/60000 [===================>] ETA: 130 s loss: 0.0120  acc: 97.8833 - lossValid: 0.0048  accValid: 99.0800 \n",
      "Epochs: 15 \\ 60 \n",
      "60000/60000 [===================>] ETA: 131 s loss: 0.0124  acc: 97.8000 - lossValid: 0.0050  accValid: 99.0400 \n",
      "Epochs: 16 \\ 60 \n",
      "60000/60000 [===================>] ETA: 131 s loss: 0.0122  acc: 97.8483 - lossValid: 0.0048  accValid: 99.0300 \n",
      "Epochs: 17 \\ 60 \n",
      "60000/60000 [===================>] ETA: 131 s loss: 0.0120  acc: 97.8583 - lossValid: 0.0047  accValid: 99.0900 \n",
      "Epochs: 18 \\ 60 \n",
      "60000/60000 [===================>] ETA: 130 s loss: 0.0119  acc: 97.9717 - lossValid: 0.0047  accValid: 99.1100 \n",
      "Epochs: 19 \\ 60 \n",
      "60000/60000 [===================>] ETA: 129 s loss: 0.0113  acc: 98.0133 - lossValid: 0.0046  accValid: 99.1100 \n",
      "Epochs: 20 \\ 60 \n",
      "60000/60000 [===================>] ETA: 129 s loss: 0.0115  acc: 97.9167 - lossValid: 0.0047  accValid: 99.0600 \n",
      "Epochs: 21 \\ 60 \n",
      "60000/60000 [===================>] ETA: 129 s loss: 0.0115  acc: 98.0017 - lossValid: 0.0046  accValid: 99.1100 \n",
      "Epochs: 22 \\ 60 \n",
      " 2400/60000 [>...................] ETA: 125 s - loss: 0.0122  acc: 98.16670"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-d82f756fe710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m               \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m               \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m               keep_prop = 0.1)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-1a21bfc9a4be>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(weights, x_train, y_train, x_valid, y_valid, epochs, nbatchs, alpha, decay, beta1, beta2, eps, l2, keep_prop)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msloss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mADAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minter_adam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-75ddc32fb1b8>\u001b[0m in \u001b[0;36mADAM\u001b[0;34m(weights, x, t, outputs, eta, beta1, beta2, eps, i, nabla, cache)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mdw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mw1_delta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnabla\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mmw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmw1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdw1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmw1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mvw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvw1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdw1\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mvt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvw1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alpha = 1e-3\n",
    "epochs = 60\n",
    "nbatchs = 100\n",
    "weights, history = run(weights, \n",
    "              x_train, d_train, \n",
    "              x_valid, d_valid, \n",
    "              epochs = epochs,\n",
    "              nbatchs=nbatchs, \n",
    "              alpha = alpha, \n",
    "              decay = 0.2, \n",
    "              beta1=0.9, \n",
    "              beta2=0.999,\n",
    "              eps=1e-8,\n",
    "              l2 = 1e-7, \n",
    "              keep_prop = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 60000\n",
      "Validation data: 10000 \n",
      "\n",
      "\n",
      "Epochs:  1 \\ 30 \n",
      "60000/60000 [===================>] ETA: 145 s loss: 0.0619  acc: 88.5083 - lossValid: 0.0162  accValid: 97.0900 \n",
      "Epochs:  2 \\ 30 \n",
      "60000/60000 [===================>] ETA: 146 s loss: 0.0351  acc: 93.9267 - lossValid: 0.0125  accValid: 97.9000 \n",
      "Epochs:  3 \\ 30 \n",
      "60000/60000 [===================>] ETA: 143 s loss: 0.0295  acc: 94.7983 - lossValid: 0.0110  accValid: 98.1300 \n",
      "Epochs:  4 \\ 30 \n",
      "60000/60000 [===================>] ETA: 144 s loss: 0.0254  acc: 95.4283 - lossValid: 0.0091  accValid: 98.5000 \n",
      "Epochs:  5 \\ 30 \n",
      "60000/60000 [===================>] ETA: 144 s loss: 0.0230  acc: 95.9733 - lossValid: 0.0078  accValid: 98.5800 \n",
      "Epochs:  6 \\ 30 \n",
      "60000/60000 [===================>] ETA: 144 s loss: 0.0213  acc: 96.2800 - lossValid: 0.0069  accValid: 98.8700 \n",
      "Epochs:  7 \\ 30 \n",
      "60000/60000 [===================>] ETA: 151 s loss: 0.0197  acc: 96.5483 - lossValid: 0.0072  accValid: 98.8600 \n",
      "Epochs:  8 \\ 30 \n",
      "34000/60000 [==========>.........] ETA:  66 s - loss: 0.0184  acc: 96.7265"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in multiply\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [===================>] ETA: 156 s loss: 0.0186  acc: 96.7533 - lossValid: 0.0065  accValid: 98.8400 \n",
      "Epochs:  9 \\ 30 \n",
      "60000/60000 [===================>] ETA: 162 s loss: 0.0173  acc: 97.0783 - lossValid: 0.0065  accValid: 98.8300 \n",
      "Epochs: 10 \\ 30 \n",
      "60000/60000 [===================>] ETA: 154 s loss: 0.0165  acc: 97.1467 - lossValid: 0.0066  accValid: 98.8200 \n",
      "Epochs: 11 \\ 30 \n",
      "60000/60000 [===================>] ETA: 171 s loss: 0.0160  acc: 97.2233 - lossValid: 0.0065  accValid: 98.9000 \n",
      "Epochs: 12 \\ 30 \n",
      "60000/60000 [===================>] ETA: 173 s loss: 0.0154  acc: 97.3767 - lossValid: 0.0056  accValid: 99.0100 \n",
      "Epochs: 13 \\ 30 \n",
      "60000/60000 [===================>] ETA: 177 s loss: 0.0148  acc: 97.4100 - lossValid: 0.0058  accValid: 99.0200 \n",
      "Epochs: 14 \\ 30 \n",
      "60000/60000 [===================>] ETA: 175 s loss: 0.0140  acc: 97.6067 - lossValid: 0.0053  accValid: 99.0000 \n",
      "Epochs: 15 \\ 30 \n",
      "60000/60000 [===================>] ETA: 172 s loss: 0.0130  acc: 97.7950 - lossValid: 0.0050  accValid: 99.0500 \n",
      "Epochs: 16 \\ 30 \n",
      "60000/60000 [===================>] ETA: 170 s loss: 0.0127  acc: 97.7500 - lossValid: 0.0047  accValid: 99.2300 \n",
      "Epochs: 17 \\ 30 \n",
      "60000/60000 [===================>] ETA: 172 s loss: 0.0128  acc: 97.7400 - lossValid: 0.0050  accValid: 99.1500 \n",
      "Epochs: 18 \\ 30 \n",
      "60000/60000 [===================>] ETA: 143 s loss: 0.0124  acc: 97.8400 - lossValid: 0.0048  accValid: 99.1400 \n",
      "Epochs: 19 \\ 30 \n",
      "60000/60000 [===================>] ETA: 143 s loss: 0.0123  acc: 97.8217 - lossValid: 0.0046  accValid: 99.2100 \n",
      "Epochs: 20 \\ 30 \n",
      "60000/60000 [===================>] ETA: 143 s loss: 0.0112  acc: 98.0633 - lossValid: 0.0044  accValid: 99.1700 \n",
      "Epochs: 21 \\ 30 \n",
      "60000/60000 [===================>] ETA: 145 s loss: 0.0117  acc: 98.0033 - lossValid: 0.0047  accValid: 99.2800 \n",
      "Epochs: 22 \\ 30 \n",
      "60000/60000 [===================>] ETA: 140 s loss: 0.0117  acc: 98.0117 - lossValid: 0.0045  accValid: 99.2400 \n",
      "Epochs: 23 \\ 30 \n",
      "60000/60000 [===================>] ETA: 145 s loss: 0.0110  acc: 98.0633 - lossValid: 0.0045  accValid: 99.2800 \n",
      "Epochs: 24 \\ 30 \n",
      "60000/60000 [===================>] ETA: 145 s loss: 0.0109  acc: 98.1083 - lossValid: 0.0045  accValid: 99.2900 \n",
      "Epochs: 25 \\ 30 \n",
      "60000/60000 [===================>] ETA: 144 s loss: 0.0105  acc: 98.2117 - lossValid: 0.0044  accValid: 99.2900 \n",
      "Epochs: 26 \\ 30 \n",
      "60000/60000 [===================>] ETA: 143 s loss: 0.0104  acc: 98.1733 - lossValid: 0.0043  accValid: 99.2300 \n",
      "Epochs: 27 \\ 30 \n",
      "60000/60000 [===================>] ETA: 144 s loss: 0.0105  acc: 98.1833 - lossValid: 0.0043  accValid: 99.2500 \n",
      "Epochs: 28 \\ 30 \n",
      "60000/60000 [===================>] ETA: 144 s loss: 0.0104  acc: 98.1817 - lossValid: 0.0044  accValid: 99.1900 \n",
      "Epochs: 29 \\ 30 \n",
      "60000/60000 [===================>] ETA: 144 s loss: 0.0104  acc: 98.2150 - lossValid: 0.0044  accValid: 99.2000 \n",
      "Epochs: 30 \\ 30 \n",
      "60000/60000 [===================>] ETA: 143 s loss: 0.0100  acc: 98.3133 - lossValid: 0.0042  accValid: 99.2600 "
     ]
    }
   ],
   "source": [
    "weights = CreateWeights(2500, 200)\n",
    "\n",
    "alpha = 1e-3\n",
    "epochs = 30\n",
    "nbatchs = 100\n",
    "weights, history = run(weights, \n",
    "              x_train, d_train, \n",
    "              x_valid, d_valid, \n",
    "              epochs = epochs,\n",
    "              nbatchs=nbatchs, \n",
    "              alpha = alpha, \n",
    "              decay = 0.1, \n",
    "              beta1=0.9, \n",
    "              beta2=0.999,\n",
    "              eps=1e-8,\n",
    "              l2 = 1e-7, \n",
    "              keep_prop = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 60000\n",
      "Validation data: 10000 \n",
      "\n",
      "\n",
      "Epochs:  1 \\ 70 \n",
      "60000/60000 [===================>] ETA: 312 s loss: 0.0571  acc: 89.1450 - lossValid: 0.0150  accValid: 97.4700 \n",
      "Epochs:  2 \\ 70 \n",
      "60000/60000 [===================>] ETA: 306 s loss: 0.0345  acc: 93.9033 - lossValid: 0.0116  accValid: 97.8700 \n",
      "Epochs:  3 \\ 70 \n",
      "60000/60000 [===================>] ETA: 349 s loss: 0.0277  acc: 95.1833 - lossValid: 0.0115  accValid: 97.9800 \n",
      "Epochs:  4 \\ 70 \n",
      "60000/60000 [===================>] ETA: 358 s loss: 0.0255  acc: 95.5917 - lossValid: 0.0082  accValid: 98.5800 \n",
      "Epochs:  5 \\ 70 \n",
      "60000/60000 [===================>] ETA: 317 s loss: 0.0224  acc: 96.0333 - lossValid: 0.0078  accValid: 98.7100 \n",
      "Epochs:  6 \\ 70 \n",
      "14100/60000 [====>...............] ETA: 237 s - loss: 0.0201  acc: 96.4539"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in multiply\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [===================>] ETA: 305 s loss: 0.0205  acc: 96.4233 - lossValid: 0.0085  accValid: 98.5700 \n",
      "Epochs:  7 \\ 70 \n",
      "60000/60000 [===================>] ETA: 307 s loss: 0.0190  acc: 96.7250 - lossValid: 0.0064  accValid: 98.9300 \n",
      "Epochs:  8 \\ 70 \n",
      "60000/60000 [===================>] ETA: 307 s loss: 0.0176  acc: 96.8733 - lossValid: 0.0059  accValid: 98.9700 \n",
      "Epochs:  9 \\ 70 \n",
      "60000/60000 [===================>] ETA: 299 s loss: 0.0166  acc: 97.0767 - lossValid: 0.0065  accValid: 98.9900 \n",
      "Epochs: 10 \\ 70 \n",
      "60000/60000 [===================>] ETA: 305 s loss: 0.0162  acc: 97.1967 - lossValid: 0.0058  accValid: 98.9300 \n",
      "Epochs: 11 \\ 70 \n",
      "60000/60000 [===================>] ETA: 308 s loss: 0.0148  acc: 97.5133 - lossValid: 0.0054  accValid: 99.1000 \n",
      "Epochs: 12 \\ 70 \n",
      "60000/60000 [===================>] ETA: 308 s loss: 0.0142  acc: 97.5150 - lossValid: 0.0051  accValid: 99.1600 \n",
      "Epochs: 13 \\ 70 \n",
      "60000/60000 [===================>] ETA: 302 s loss: 0.0131  acc: 97.7117 - lossValid: 0.0051  accValid: 99.0700 \n",
      "Epochs: 14 \\ 70 \n",
      "60000/60000 [===================>] ETA: 310 s loss: 0.0132  acc: 97.7233 - lossValid: 0.0048  accValid: 99.1800 \n",
      "Epochs: 15 \\ 70 \n",
      "60000/60000 [===================>] ETA: 303 s loss: 0.0124  acc: 97.8683 - lossValid: 0.0048  accValid: 99.1800 \n",
      "Epochs: 16 \\ 70 \n",
      "60000/60000 [===================>] ETA: 313 s loss: 0.0120  acc: 97.8433 - lossValid: 0.0048  accValid: 99.1600 \n",
      "Epochs: 17 \\ 70 \n",
      "60000/60000 [===================>] ETA: 301 s loss: 0.0118  acc: 98.0200 - lossValid: 0.0045  accValid: 99.2500 \n",
      "Epochs: 18 \\ 70 \n",
      "60000/60000 [===================>] ETA: 306 s loss: 0.0108  acc: 98.1350 - lossValid: 0.0047  accValid: 99.1700 \n",
      "Epochs: 19 \\ 70 \n",
      "60000/60000 [===================>] ETA: 305 s loss: 0.0111  acc: 98.1283 - lossValid: 0.0043  accValid: 99.2500 \n",
      "Epochs: 20 \\ 70 \n",
      "60000/60000 [===================>] ETA: 297 s loss: 0.0106  acc: 98.1017 - lossValid: 0.0040  accValid: 99.3100 \n",
      "Epochs: 21 \\ 70 \n",
      "60000/60000 [===================>] ETA: 311 s loss: 0.0104  acc: 98.1900 - lossValid: 0.0042  accValid: 99.2700 \n",
      "Epochs: 22 \\ 70 \n",
      "60000/60000 [===================>] ETA: 316 s loss: 0.0103  acc: 98.2283 - lossValid: 0.0043  accValid: 99.1900 \n",
      "Epochs: 23 \\ 70 \n",
      "60000/60000 [===================>] ETA: 319 s loss: 0.0096  acc: 98.3150 - lossValid: 0.0040  accValid: 99.2400 \n",
      "Epochs: 24 \\ 70 \n",
      "60000/60000 [===================>] ETA: 320 s loss: 0.0094  acc: 98.3900 - lossValid: 0.0038  accValid: 99.2900 \n",
      "Epochs: 25 \\ 70 \n",
      "60000/60000 [===================>] ETA: 317 s loss: 0.0095  acc: 98.3533 - lossValid: 0.0040  accValid: 99.2900 \n",
      "Epochs: 26 \\ 70 \n",
      "60000/60000 [===================>] ETA: 316 s loss: 0.0093  acc: 98.3700 - lossValid: 0.0038  accValid: 99.2900 \n",
      "Epochs: 27 \\ 70 \n",
      "60000/60000 [===================>] ETA: 332 s loss: 0.0093  acc: 98.3217 - lossValid: 0.0039  accValid: 99.2100 \n",
      "Epochs: 28 \\ 70 \n",
      "60000/60000 [===================>] ETA: 348 s loss: 0.0089  acc: 98.4633 - lossValid: 0.0037  accValid: 99.3200 \n",
      "Epochs: 29 \\ 70 \n",
      "60000/60000 [===================>] ETA: 317 s loss: 0.0086  acc: 98.5317 - lossValid: 0.0039  accValid: 99.2900 \n",
      "Epochs: 30 \\ 70 \n",
      "60000/60000 [===================>] ETA: 311 s loss: 0.0087  acc: 98.4533 - lossValid: 0.0040  accValid: 99.2500 \n",
      "Epochs: 31 \\ 70 \n",
      "60000/60000 [===================>] ETA: 355 s loss: 0.0083  acc: 98.5083 - lossValid: 0.0039  accValid: 99.3000 \n",
      "Epochs: 32 \\ 70 \n",
      "60000/60000 [===================>] ETA: 317 s loss: 0.0089  acc: 98.4367 - lossValid: 0.0039  accValid: 99.2800 \n",
      "Epochs: 33 \\ 70 \n",
      "60000/60000 [===================>] ETA: 309 s loss: 0.0087  acc: 98.5417 - lossValid: 0.0038  accValid: 99.3200 \n",
      "Epochs: 34 \\ 70 \n",
      "60000/60000 [===================>] ETA: 307 s loss: 0.0083  acc: 98.5250 - lossValid: 0.0037  accValid: 99.3000 \n",
      "Epochs: 35 \\ 70 \n",
      "60000/60000 [===================>] ETA: 318 s loss: 0.0084  acc: 98.4900 - lossValid: 0.0038  accValid: 99.2600 \n",
      "Epochs: 36 \\ 70 \n",
      "60000/60000 [===================>] ETA: 354 s loss: 0.0076  acc: 98.6617 - lossValid: 0.0038  accValid: 99.2400 \n",
      "Epochs: 37 \\ 70 \n",
      "60000/60000 [===================>] ETA: 316 s loss: 0.0082  acc: 98.6033 - lossValid: 0.0039  accValid: 99.2700 \n",
      "Epochs: 38 \\ 70 \n",
      "60000/60000 [===================>] ETA: 305 s loss: 0.0081  acc: 98.6383 - lossValid: 0.0038  accValid: 99.2500 \n",
      "Epochs: 39 \\ 70 \n",
      "60000/60000 [===================>] ETA: 303 s loss: 0.0079  acc: 98.6267 - lossValid: 0.0038  accValid: 99.2700 \n",
      "Epochs: 40 \\ 70 \n",
      "60000/60000 [===================>] ETA: 306 s loss: 0.0081  acc: 98.5817 - lossValid: 0.0037  accValid: 99.2800 \n",
      "Epochs: 41 \\ 70 \n",
      "60000/60000 [===================>] ETA: 298 s loss: 0.0082  acc: 98.5917 - lossValid: 0.0037  accValid: 99.2600 \n",
      "Epochs: 42 \\ 70 \n",
      "60000/60000 [===================>] ETA: 307 s loss: 0.0077  acc: 98.6317 - lossValid: 0.0038  accValid: 99.2700 \n",
      "Epochs: 43 \\ 70 \n",
      "60000/60000 [===================>] ETA: 303 s loss: 0.0081  acc: 98.5950 - lossValid: 0.0037  accValid: 99.2700 \n",
      "Epochs: 44 \\ 70 \n",
      "60000/60000 [===================>] ETA: 311 s loss: 0.0082  acc: 98.6117 - lossValid: 0.0038  accValid: 99.2600 \n",
      "Epochs: 45 \\ 70 \n",
      "60000/60000 [===================>] ETA: 302 s loss: 0.0081  acc: 98.6267 - lossValid: 0.0037  accValid: 99.3000 \n",
      "Epochs: 46 \\ 70 \n",
      "60000/60000 [===================>] ETA: 310 s loss: 0.0081  acc: 98.5600 - lossValid: 0.0038  accValid: 99.2900 \n",
      "Epochs: 47 \\ 70 \n",
      "60000/60000 [===================>] ETA: 305 s loss: 0.0079  acc: 98.6550 - lossValid: 0.0037  accValid: 99.2600 \n",
      "Epochs: 48 \\ 70 \n",
      "60000/60000 [===================>] ETA: 304 s loss: 0.0079  acc: 98.6350 - lossValid: 0.0037  accValid: 99.2800 \n",
      "Epochs: 49 \\ 70 \n",
      "60000/60000 [===================>] ETA: 305 s loss: 0.0077  acc: 98.7183 - lossValid: 0.0037  accValid: 99.2900 \n",
      "Epochs: 50 \\ 70 \n",
      "60000/60000 [===================>] ETA: 310 s loss: 0.0079  acc: 98.6133 - lossValid: 0.0037  accValid: 99.2900 \n",
      "Epochs: 51 \\ 70 \n",
      "60000/60000 [===================>] ETA: 309 s loss: 0.0075  acc: 98.6717 - lossValid: 0.0037  accValid: 99.2800 \n",
      "Epochs: 52 \\ 70 \n",
      "60000/60000 [===================>] ETA: 306 s loss: 0.0077  acc: 98.6483 - lossValid: 0.0037  accValid: 99.2700 \n",
      "Epochs: 53 \\ 70 \n",
      "60000/60000 [===================>] ETA: 307 s loss: 0.0079  acc: 98.6000 - lossValid: 0.0037  accValid: 99.2700 \n",
      "Epochs: 54 \\ 70 \n",
      "60000/60000 [===================>] ETA: 305 s loss: 0.0078  acc: 98.6300 - lossValid: 0.0037  accValid: 99.2800 \n",
      "Epochs: 55 \\ 70 \n",
      "60000/60000 [===================>] ETA: 304 s loss: 0.0077  acc: 98.6067 - lossValid: 0.0037  accValid: 99.2900 \n",
      "Epochs: 56 \\ 70 \n",
      "60000/60000 [===================>] ETA: 305 s loss: 0.0077  acc: 98.6750 - lossValid: 0.0037  accValid: 99.2800 \n",
      "Epochs: 57 \\ 70 \n",
      "60000/60000 [===================>] ETA: 315 s loss: 0.0081  acc: 98.6467 - lossValid: 0.0037  accValid: 99.2900 \n",
      "Epochs: 58 \\ 70 \n",
      "60000/60000 [===================>] ETA: 300 s loss: 0.0077  acc: 98.6883 - lossValid: 0.0037  accValid: 99.2900 \n",
      "Epochs: 59 \\ 70 \n",
      "60000/60000 [===================>] ETA: 313 s loss: 0.0079  acc: 98.6100 - lossValid: 0.0037  accValid: 99.2900 \n",
      "Epochs: 60 \\ 70 \n",
      "60000/60000 [===================>] ETA: 310 s loss: 0.0080  acc: 98.5883 - lossValid: 0.0037  accValid: 99.2900 \n",
      "Epochs: 61 \\ 70 \n",
      "60000/60000 [===================>] ETA: 310 s loss: 0.0079  acc: 98.5900 - lossValid: 0.0037  accValid: 99.2900 \n",
      "Epochs: 62 \\ 70 \n",
      "60000/60000 [===================>] ETA: 313 s loss: 0.0078  acc: 98.6783 - lossValid: 0.0037  accValid: 99.2800 \n",
      "Epochs: 63 \\ 70 \n",
      "60000/60000 [===================>] ETA: 314 s loss: 0.0080  acc: 98.5967 - lossValid: 0.0037  accValid: 99.2700 \n",
      "Epochs: 64 \\ 70 \n",
      "60000/60000 [===================>] ETA: 305 s loss: 0.0078  acc: 98.6183 - lossValid: 0.0037  accValid: 99.2700 \n",
      "Epochs: 65 \\ 70 \n",
      "60000/60000 [===================>] ETA: 304 s loss: 0.0077  acc: 98.6783 - lossValid: 0.0037  accValid: 99.2700 \n",
      "Epochs: 66 \\ 70 \n",
      "60000/60000 [===================>] ETA: 302 s loss: 0.0076  acc: 98.6467 - lossValid: 0.0037  accValid: 99.2700 \n",
      "Epochs: 67 \\ 70 \n",
      "60000/60000 [===================>] ETA: 306 s loss: 0.0077  acc: 98.6633 - lossValid: 0.0037  accValid: 99.2800 \n",
      "Epochs: 68 \\ 70 \n",
      "60000/60000 [===================>] ETA: 305 s loss: 0.0079  acc: 98.5917 - lossValid: 0.0037  accValid: 99.2800 \n",
      "Epochs: 69 \\ 70 \n",
      "60000/60000 [===================>] ETA: 307 s loss: 0.0075  acc: 98.7217 - lossValid: 0.0037  accValid: 99.2800 \n",
      "Epochs: 70 \\ 70 \n",
      "60000/60000 [===================>] ETA: 304 s loss: 0.0076  acc: 98.6767 - lossValid: 0.0037  accValid: 99.2800 "
     ]
    }
   ],
   "source": [
    "weights = CreateWeights(2500, 2000)\n",
    "\n",
    "alpha = 1e-3\n",
    "epochs = 70\n",
    "nbatchs = 100\n",
    "weights, history = run(weights, \n",
    "              x_train, d_train, \n",
    "              x_valid, d_valid, \n",
    "              epochs = epochs,\n",
    "              nbatchs=nbatchs, \n",
    "              alpha = alpha, \n",
    "              decay = 0.1, \n",
    "              beta1=0.9, \n",
    "              beta2=0.999,\n",
    "              eps=1e-8,\n",
    "              l2 = 1e-7, \n",
    "              keep_prop = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 60000\n",
      "Validation data: 10000 \n",
      "\n",
      "\n",
      "Epochs:  1 \\ 30 \n",
      "60000/60000 [===================>] ETA:  97 s loss: 0.0868  acc: 83.2267 - lossValid: 0.0214  accValid: 96.1200 \n",
      "Epochs:  2 \\ 30 \n",
      "60000/60000 [===================>] ETA:  97 s loss: 0.0532  acc: 90.3567 - lossValid: 0.0153  accValid: 97.4000 \n",
      "Epochs:  3 \\ 30 \n",
      "60000/60000 [===================>] ETA:  99 s loss: 0.0453  acc: 91.8533 - lossValid: 0.0139  accValid: 97.7100 \n",
      "Epochs:  4 \\ 30 \n",
      "60000/60000 [===================>] ETA:  98 s loss: 0.0411  acc: 92.7233 - lossValid: 0.0128  accValid: 97.8100 \n",
      "Epochs:  5 \\ 30 \n",
      "60000/60000 [===================>] ETA: 100 s loss: 0.0380  acc: 93.3433 - lossValid: 0.0114  accValid: 98.1200 \n",
      "Epochs:  6 \\ 30 \n",
      "60000/60000 [===================>] ETA:  98 s loss: 0.0357  acc: 93.5233 - lossValid: 0.0115  accValid: 98.0500 \n",
      "Epochs:  7 \\ 30 \n",
      "60000/60000 [===================>] ETA:  98 s loss: 0.0346  acc: 93.8500 - lossValid: 0.0104  accValid: 98.2100 \n",
      "Epochs:  8 \\ 30 \n",
      "60000/60000 [===================>] ETA:  98 s loss: 0.0327  acc: 94.2400 - lossValid: 0.0097  accValid: 98.3200 \n",
      "Epochs:  9 \\ 30 \n",
      "60000/60000 [===================>] ETA:  99 s loss: 0.0317  acc: 94.3717 - lossValid: 0.0094  accValid: 98.3400 \n",
      "Epochs: 10 \\ 30 \n",
      "60000/60000 [===================>] ETA: 100 s loss: 0.0312  acc: 94.5000 - lossValid: 0.0090  accValid: 98.4000 \n",
      "Epochs: 11 \\ 30 \n",
      "60000/60000 [===================>] ETA:  98 s loss: 0.0312  acc: 94.5167 - lossValid: 0.0091  accValid: 98.3900 \n",
      "Epochs: 12 \\ 30 \n",
      "60000/60000 [===================>] ETA:  98 s loss: 0.0297  acc: 94.7217 - lossValid: 0.0087  accValid: 98.4600 \n",
      "Epochs: 13 \\ 30 \n",
      "60000/60000 [===================>] ETA:  98 s loss: 0.0294  acc: 94.7383 - lossValid: 0.0085  accValid: 98.4500 \n",
      "Epochs: 14 \\ 30 \n",
      "60000/60000 [===================>] ETA:  98 s loss: 0.0296  acc: 94.9017 - lossValid: 0.0086  accValid: 98.4900 \n",
      "Epochs: 15 \\ 30 \n",
      "60000/60000 [===================>] ETA: 101 s loss: 0.0296  acc: 94.8067 - lossValid: 0.0087  accValid: 98.4800 \n",
      "Epochs: 16 \\ 30 \n",
      "60000/60000 [===================>] ETA: 115 s loss: 0.0283  acc: 94.9100 - lossValid: 0.0084  accValid: 98.5100 \n",
      "Epochs: 17 \\ 30 \n",
      "60000/60000 [===================>] ETA: 129 s loss: 0.0290  acc: 94.8133 - lossValid: 0.0084  accValid: 98.5000 \n",
      "Epochs: 18 \\ 30 \n",
      "60000/60000 [===================>] ETA: 135 s loss: 0.0279  acc: 94.9717 - lossValid: 0.0084  accValid: 98.4900 \n",
      "Epochs: 19 \\ 30 \n",
      "60000/60000 [===================>] ETA: 133 s loss: 0.0283  acc: 95.0200 - lossValid: 0.0084  accValid: 98.5100 \n",
      "Epochs: 20 \\ 30 \n",
      "60000/60000 [===================>] ETA: 136 s loss: 0.0286  acc: 94.9650 - lossValid: 0.0084  accValid: 98.5000 \n",
      "Epochs: 21 \\ 30 \n",
      "60000/60000 [===================>] ETA: 132 s loss: 0.0290  acc: 94.8250 - lossValid: 0.0085  accValid: 98.4700 \n",
      "Epochs: 22 \\ 30 \n",
      "60000/60000 [===================>] ETA: 131 s loss: 0.0284  acc: 94.9283 - lossValid: 0.0083  accValid: 98.4900 \n",
      "Epochs: 23 \\ 30 \n",
      "60000/60000 [===================>] ETA: 145 s loss: 0.0279  acc: 95.1383 - lossValid: 0.0084  accValid: 98.4900 \n",
      "Epochs: 24 \\ 30 \n",
      "60000/60000 [===================>] ETA: 150 s loss: 0.0280  acc: 94.9967 - lossValid: 0.0084  accValid: 98.4700 \n",
      "Epochs: 25 \\ 30 \n",
      "60000/60000 [===================>] ETA: 121 s loss: 0.0278  acc: 95.1050 - lossValid: 0.0084  accValid: 98.4700 \n",
      "Epochs: 26 \\ 30 \n",
      "60000/60000 [===================>] ETA: 135 s loss: 0.0279  acc: 95.0167 - lossValid: 0.0083  accValid: 98.4700 \n",
      "Epochs: 27 \\ 30 \n",
      "60000/60000 [===================>] ETA: 153 s loss: 0.0287  acc: 94.9650 - lossValid: 0.0083  accValid: 98.5000 \n",
      "Epochs: 28 \\ 30 \n",
      "60000/60000 [===================>] ETA: 150 s loss: 0.0281  acc: 95.0767 - lossValid: 0.0083  accValid: 98.5100 \n",
      "Epochs: 29 \\ 30 \n",
      "60000/60000 [===================>] ETA: 141 s loss: 0.0284  acc: 94.8650 - lossValid: 0.0083  accValid: 98.5000 \n",
      "Epochs: 30 \\ 30 \n",
      "60000/60000 [===================>] ETA: 132 s loss: 0.0278  acc: 95.0433 - lossValid: 0.0083  accValid: 98.5100 "
     ]
    }
   ],
   "source": [
    "weights = CreateWeights(200, 2000)\n",
    "\n",
    "alpha = 1e-3\n",
    "epochs = 30\n",
    "nbatchs = 100\n",
    "weights, history = run(weights, \n",
    "              x_train, d_train, \n",
    "              x_valid, d_valid, \n",
    "              epochs = epochs,\n",
    "              nbatchs=nbatchs, \n",
    "              alpha = alpha, \n",
    "              decay = 0.2, \n",
    "              beta1=0.9, \n",
    "              beta2=0.999,\n",
    "              eps=1e-8,\n",
    "              l2 = 1e-7, \n",
    "              keep_prop = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 60000\n",
      "Validation data: 10000 \n",
      "\n",
      "\n",
      "Epochs:  1 \\ 30 \n",
      "60000/60000 [===================>] ETA: 180 s loss: 0.0599  acc: 88.8117 - lossValid: 0.0148  accValid: 97.2400 \n",
      "Epochs:  2 \\ 30 \n",
      "60000/60000 [===================>] ETA: 185 s loss: 0.0315  acc: 94.5650 - lossValid: 0.0108  accValid: 98.1000 \n",
      "Epochs:  3 \\ 30 \n",
      "60000/60000 [===================>] ETA: 178 s loss: 0.0249  acc: 95.6000 - lossValid: 0.0087  accValid: 98.4000 \n",
      "Epochs:  4 \\ 30 \n",
      "60000/60000 [===================>] ETA: 174 s loss: 0.0211  acc: 96.2983 - lossValid: 0.0077  accValid: 98.6200 \n",
      "Epochs:  5 \\ 30 \n",
      "60000/60000 [===================>] ETA: 176 s loss: 0.0191  acc: 96.6700 - lossValid: 0.0075  accValid: 98.6800 \n",
      "Epochs:  6 \\ 30 \n",
      "60000/60000 [===================>] ETA: 181 s loss: 0.0178  acc: 96.8650 - lossValid: 0.0066  accValid: 98.8300 \n",
      "Epochs:  7 \\ 30 \n",
      "60000/60000 [===================>] ETA: 172 s loss: 0.0161  acc: 97.2600 - lossValid: 0.0072  accValid: 98.7100 \n",
      "Epochs:  8 \\ 30 \n",
      "60000/60000 [===================>] ETA: 184 s loss: 0.0151  acc: 97.4367 - lossValid: 0.0058  accValid: 98.9500 \n",
      "Epochs:  9 \\ 30 \n",
      "60000/60000 [===================>] ETA: 189 s loss: 0.0145  acc: 97.5350 - lossValid: 0.0057  accValid: 98.9500 \n",
      "Epochs: 10 \\ 30 \n",
      " 2800/60000 [>...................] ETA: 174 s - loss: 0.0145  acc: 97.6071"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [===================>] ETA: 216 s loss: 0.0120  acc: 97.9333 - lossValid: 0.0050  accValid: 99.0600 \n",
      "Epochs: 15 \\ 30 \n",
      "60000/60000 [===================>] ETA: 215 s loss: 0.0118  acc: 98.0167 - lossValid: 0.0049  accValid: 99.1400 \n",
      "Epochs: 16 \\ 30 \n",
      "60000/60000 [===================>] ETA: 211 s loss: 0.0114  acc: 97.9883 - lossValid: 0.0048  accValid: 99.1200 \n",
      "Epochs: 17 \\ 30 \n",
      "24100/60000 [=======>............] ETA: 130 s - loss: 0.0120  acc: 97.9004"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in multiply\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [===================>] ETA: 239 s loss: 0.0115  acc: 97.9883 - lossValid: 0.0049  accValid: 99.1200 \n",
      "Epochs: 18 \\ 30 \n",
      "60000/60000 [===================>] ETA: 270 s loss: 0.0117  acc: 98.0167 - lossValid: 0.0047  accValid: 99.1600 \n",
      "Epochs: 19 \\ 30 \n",
      "  100/60000 [....................] ETA: 239 s - loss: 0.0172  acc: 97.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [===================>] ETA: 269 s loss: 0.0113  acc: 98.0850 - lossValid: 0.0046  accValid: 99.1800 \n",
      "Epochs: 23 \\ 30 \n",
      "60000/60000 [===================>] ETA: 210 s loss: 0.0109  acc: 98.1050 - lossValid: 0.0046  accValid: 99.1800 \n",
      "Epochs: 24 \\ 30 \n",
      "60000/60000 [===================>] ETA: 231 s loss: 0.0108  acc: 98.1833 - lossValid: 0.0047  accValid: 99.1600 \n",
      "Epochs: 25 \\ 30 \n",
      "60000/60000 [===================>] ETA: 215 s loss: 0.0107  acc: 98.1650 - lossValid: 0.0046  accValid: 99.1600 \n",
      "Epochs: 26 \\ 30 \n",
      "60000/60000 [===================>] ETA: 213 s loss: 0.0110  acc: 98.0917 - lossValid: 0.0046  accValid: 99.1400 \n",
      "Epochs: 27 \\ 30 \n",
      "60000/60000 [===================>] ETA: 207 s loss: 0.0108  acc: 98.1100 - lossValid: 0.0046  accValid: 99.1800 \n",
      "Epochs: 28 \\ 30 \n",
      "60000/60000 [===================>] ETA: 211 s loss: 0.0111  acc: 98.0800 - lossValid: 0.0047  accValid: 99.1500 \n",
      "Epochs: 29 \\ 30 \n",
      "60000/60000 [===================>] ETA: 202 s loss: 0.0106  acc: 98.1800 - lossValid: 0.0047  accValid: 99.1700 \n",
      "Epochs: 30 \\ 30 \n",
      "60000/60000 [===================>] ETA: 211 s loss: 0.0108  acc: 98.1250 - lossValid: 0.0046  accValid: 99.1500 "
     ]
    }
   ],
   "source": [
    "weights = CreateWeights(3000, 100)\n",
    "\n",
    "alpha = 1e-3\n",
    "epochs = 30\n",
    "nbatchs = 100\n",
    "weights, history = run(weights, \n",
    "              x_train, d_train, \n",
    "              x_valid, d_valid, \n",
    "              epochs = epochs,\n",
    "              nbatchs=nbatchs, \n",
    "              alpha = alpha, \n",
    "              decay = 0.2, \n",
    "              beta1=0.9, \n",
    "              beta2=0.999,\n",
    "              eps=1e-8,\n",
    "              l2 = 1e-7, \n",
    "              keep_prop = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(weights, x, t, outputs, eta, gamma, nabla, cache=None):\n",
    "    \n",
    "    w1,w2,w3,b1,b2,b3  = weights\n",
    "    \n",
    "    \n",
    "    if(cache==None):\n",
    "            vw1 = np.zeros_like(w1)\n",
    "            vw2 = np.zeros_like(w2)\n",
    "            vw3 = np.zeros_like(w3)\n",
    "            vb1 = np.zeros_like(b1)\n",
    "            vb2 = np.zeros_like(b2)\n",
    "            vb3 = np.zeros_like(b3)\n",
    "    else:\n",
    "        vw1,vw2,vw3,vb1,vb2,vb3 = cache\n",
    "    \n",
    "    first, second, y = outputs\n",
    "   \n",
    "    w3_delta = (t-y)\n",
    "    \n",
    "    w2_error = w3_delta@w3.T\n",
    "\n",
    "    w2_delta = w2_error * ReLu(second,derivative=True)\n",
    "\n",
    "    w1_error = w2_delta@w2.T\n",
    "    w1_delta = w1_error * ReLu(first,derivative=True)\n",
    "    \n",
    "    eta = -eta/x.shape[0]\n",
    "    nabla *= 2;\n",
    "    \n",
    "    vw3 = gamma*vw3 + eta * (second.T@w3_delta + nabla*w3)\n",
    "    vb3 = gamma*vb3 + eta * w3_delta.sum(axis=0)\n",
    "\n",
    "    vw2 = gamma*vw2 + eta * (first.T@w2_delta + nabla*w2)\n",
    "    vb2 = gamma*vb2 + eta * w2_delta.sum(axis=0)\n",
    "\n",
    "    vw1 = gamma*vw1 + eta * (x.T@w1_delta + nabla*w1)\n",
    "    vb1 = gamma*vb1 + eta * w1_delta.sum(axis=0)\n",
    "    \n",
    "    \n",
    "    w3 -= vw3\n",
    "    b3 -= vb3\n",
    "\n",
    "    w2 -= vw2\n",
    "    b2 -= vb2\n",
    "\n",
    "    w1 -= vw1\n",
    "    b1 -= vb1\n",
    "    \n",
    "    weights = [w1,w2,w3,b1,b2,b3]\n",
    "    cache = [vw1,vw2,vw3,vb1,vb2,vb3]\n",
    "    \n",
    "    return weights, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sgd(weights, x_train, y_train, x_valid, y_valid, epochs = 10, nbatchs=25, alpha = 1e-3, decay = 0, momentum = 0, l2 = 0.001, keep_prop = 0):\n",
    "    \n",
    "    pross = x_train.shape[0]*0.05\n",
    "    \n",
    "    history = [[],[]]\n",
    "    \n",
    "    index = np.arange(x_train.shape[0])\n",
    "    cache = None\n",
    "    print(\"Train data: %d\" % (x_train.shape[0]))\n",
    "    print(\"Validation data: %d \\n\" % (x_valid.shape[0]))\n",
    "    mtime = 0\n",
    "    \n",
    "    for j in range(epochs):\n",
    "        np.random.shuffle(index)\n",
    "        t = 0\n",
    "        iterations = round(x_train.shape[0]/nbatchs)\n",
    "        prog = \"\"\n",
    "        sacurr = 0\n",
    "        sloss = 0\n",
    "        sys.stdout.write(\"\\nEpochs: %2d \\ %2d \\n\"% (j+1,epochs))\n",
    "        stime = 0\n",
    "        timeIT = time.time()\n",
    "        for i in range(iterations):\n",
    "            timeI = time.time()\n",
    "            f = i*nbatchs\n",
    "            l = f+nbatchs\n",
    "            \n",
    "            if(l>(x_train.shape[0]-1)):\n",
    "                l = x_train.shape[0]\n",
    "                \n",
    "            x = np.array([elastic_transform(xx.reshape(28,28),15,3).reshape(784) for xx in x_train[index[f:l]]])\n",
    "            y = y_train[index[f:l]]\n",
    "\n",
    "            outputs = predict(weights, x, keep_prop)\n",
    "            \n",
    "            loss = cost(outputs[-1], y)\n",
    "            \n",
    "            \n",
    "            accuracy_t = accuracy(outputs[-1], y)\n",
    "            \n",
    "            sacurr += accuracy_t\n",
    "            sloss += loss\n",
    "            \n",
    "            accuracy_train = sacurr/(i+1)\n",
    "            loss_train = sloss/(i+1)\n",
    "            \n",
    "            weights, cache = SGD(weights, x, y, outputs, alpha, momentum, l2, cache)\n",
    "            \n",
    "            t+= x.shape[0]\n",
    "            \n",
    "            qtd = round(t/pross)\n",
    "            prog = \"[\"\n",
    "            for p in range(20):\n",
    "                if(p<qtd-1):\n",
    "                    prog += \"=\"\n",
    "                elif(p==qtd-1):\n",
    "                    prog += \">\"\n",
    "                else:\n",
    "                    prog += \".\"\n",
    "            prog += \"]\"\n",
    "\n",
    "            \n",
    "            stime += time.time()-timeI\n",
    "            mtime = stime/(i+1)\n",
    "            mTimeT = mtime * (iterations-i-1)\n",
    "            \n",
    "            sys.stdout.write(\"\\r%5d/%5d %s ETA: %3d s - loss: %.4f  acc: %.4f\" % (t, x_train.shape[0], prog, mTimeT, loss_train, accuracy_train))\n",
    "            \n",
    "            history[0].append([loss_train, accuracy_train])\n",
    "        mtime = time.time()-timeIT\n",
    "        alpha = alpha - (alpha*decay)\n",
    "        \n",
    "        outputs = predict(weights, x_valid)\n",
    "        \n",
    "        loss_valid = cost(outputs[-1], y_valid)\n",
    "        accuracy_valid = accuracy(outputs[-1], y_valid)\n",
    "        \n",
    "        sys.stdout.write(\"\\r%5d/%5d %s ETA: %3d s loss: %.4f  acc: %.4f - lossValid: %.4f  accValid: %.4f \" % ( t, x_train.shape[0], prog, mtime, loss_train, accuracy_train, loss_valid, accuracy_valid))\n",
    "        history[1].append([loss_valid, accuracy_valid])\n",
    "        \n",
    "    return weights, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = CreateWeights(784,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 60000\n",
      "Validation data: 10000 \n",
      "\n",
      "\n",
      "Epochs:  1 \\ 20 \n",
      "60000/60000 [===================>] ETA: 117 s loss: 0.0505  acc: 91.1683 - lossValid: 0.0186  accValid: 96.9400 \n",
      "Epochs:  2 \\ 20 \n",
      "60000/60000 [===================>] ETA: 116 s loss: 0.0436  acc: 92.2300 - lossValid: 0.0156  accValid: 97.2900 \n",
      "Epochs:  3 \\ 20 \n",
      "60000/60000 [===================>] ETA: 116 s loss: 0.0395  acc: 92.9950 - lossValid: 0.0136  accValid: 97.6000 \n",
      "Epochs:  4 \\ 20 \n",
      "60000/60000 [===================>] ETA: 116 s loss: 0.0357  acc: 93.7383 - lossValid: 0.0122  accValid: 97.9700 \n",
      "Epochs:  5 \\ 20 \n",
      "60000/60000 [===================>] ETA: 117 s loss: 0.0330  acc: 94.1817 - lossValid: 0.0110  accValid: 98.1600 \n",
      "Epochs:  6 \\ 20 \n",
      "60000/60000 [===================>] ETA: 116 s loss: 0.0317  acc: 94.3900 - lossValid: 0.0105  accValid: 98.1900 \n",
      "Epochs:  7 \\ 20 \n",
      "60000/60000 [===================>] ETA: 115 s loss: 0.0303  acc: 94.7117 - lossValid: 0.0101  accValid: 98.2400 \n",
      "Epochs:  8 \\ 20 \n",
      "60000/60000 [===================>] ETA: 116 s loss: 0.0286  acc: 95.0217 - lossValid: 0.0090  accValid: 98.5300 \n",
      "Epochs:  9 \\ 20 \n",
      "60000/60000 [===================>] ETA: 116 s loss: 0.0275  acc: 95.2283 - lossValid: 0.0088  accValid: 98.5300 \n",
      "Epochs: 10 \\ 20 \n",
      "60000/60000 [===================>] ETA: 117 s loss: 0.0264  acc: 95.4100 - lossValid: 0.0084  accValid: 98.5700 \n",
      "Epochs: 11 \\ 20 \n",
      "60000/60000 [===================>] ETA: 118 s loss: 0.0260  acc: 95.3367 - lossValid: 0.0080  accValid: 98.6700 \n",
      "Epochs: 12 \\ 20 \n",
      "60000/60000 [===================>] ETA: 117 s loss: 0.0251  acc: 95.5750 - lossValid: 0.0079  accValid: 98.6300 \n",
      "Epochs: 13 \\ 20 \n",
      "60000/60000 [===================>] ETA: 117 s loss: 0.0238  acc: 95.8250 - lossValid: 0.0079  accValid: 98.6100 \n",
      "Epochs: 14 \\ 20 \n",
      "60000/60000 [===================>] ETA: 118 s loss: 0.0237  acc: 95.8633 - lossValid: 0.0074  accValid: 98.7900 \n",
      "Epochs: 15 \\ 20 \n",
      "60000/60000 [===================>] ETA: 119 s loss: 0.0226  acc: 96.0233 - lossValid: 0.0071  accValid: 98.7700 \n",
      "Epochs: 16 \\ 20 \n",
      "60000/60000 [===================>] ETA: 117 s loss: 0.0222  acc: 96.1600 - lossValid: 0.0070  accValid: 98.7600 \n",
      "Epochs: 17 \\ 20 \n",
      "60000/60000 [===================>] ETA: 118 s loss: 0.0221  acc: 96.1633 - lossValid: 0.0069  accValid: 98.7900 \n",
      "Epochs: 18 \\ 20 \n",
      "60000/60000 [===================>] ETA: 118 s loss: 0.0221  acc: 96.1067 - lossValid: 0.0070  accValid: 98.7400 \n",
      "Epochs: 19 \\ 20 \n",
      "60000/60000 [===================>] ETA: 117 s loss: 0.0208  acc: 96.3500 - lossValid: 0.0066  accValid: 98.8900 \n",
      "Epochs: 20 \\ 20 \n",
      "60000/60000 [===================>] ETA: 118 s loss: 0.0205  acc: 96.4167 - lossValid: 0.0072  accValid: 98.8000 "
     ]
    }
   ],
   "source": [
    "alpha = 1e-2\n",
    "epochs = 20\n",
    "nbatchs = 100\n",
    "weights, history = run_sgd(weights, \n",
    "              x_train, d_train, \n",
    "              x_valid, d_valid, \n",
    "              epochs = epochs,\n",
    "              nbatchs=nbatchs, \n",
    "              alpha = alpha, \n",
    "              decay = alpha/(epochs*2), \n",
    "              momentum = 0.9, \n",
    "              l2 = 1e-3, \n",
    "              keep_prop = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
